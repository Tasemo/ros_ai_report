\chapter{Conclusion}
The trained model had really good accuracies on the provided test data that matched the data it was trained on. But feeding it unstructured data
from a real microphone lead to disappointing results. The biggest problems are the different length and timings of the waveform. The CNN did not do a good enough
job to abstract the general structure of the wave and focused on specific points. The test data was of couse aligned and padded with zeroes so that the problem was not
visible there. Also, the different ampltitudes of the waves probably influenced the accuracy, but applying the background noise and still getting good results shows, that
it has a lower effect than the problem with different timings. This is at least the case for relativly constant noise. All in all, it was shown that a local command
recognition system can work with a high enough accuracy, but more work is neccesary to achieve that on raw data.

\section{Summary}
We set our task to implement and evaluate a command recognition system using machine learning. We used a very deep convolutional neural network and trained it
on the "SpeechCommands" dataset. We evaluated the model using the provided test data and implemented a realistic evaluation enviroment using ROS. We tested the model
with a real microphone and got the recognition working, but with a poor accuracy.

\section{Future Work}
More work has to be done on transforming the data to the format the model was trained on. It is simply not enough to feed it audio data with
a different amplitude and a different timing. The high fluctuation in accuracies should be evaluated in more detail as well as no conclusive reason for that
was found in this report.